/**
\mainpage
\author Aditya Kashi

TADGENS
=======
A 2D, unstructured grid, discontinuous Galerkin (DG) solver for the compressible Euler equations.

Mathematical details
====================

1D Lagrange basis functions
---------------------------
Reference element: \f$ \xi \in [-1,1] \f$
P1 elements: \f$ \phi_1(\xi) = \frac{1-\xi}{2}, \phi_2(\xi) = \frac{1+\xi}{2} \f$.
P2 elements: \f$ \phi_1(\xi) = \frac{\xi(\xi-1)}{2}, \phi_2(\xi) = \frac{\xi(\xi+1)}{2}, \phi_3(\xi) = 1-\xi^2 \f$.

Implementation details
======================

Storage of mesh data
--------------------
Mesh data, including coordinates of nodes (coord), interconnectivity matrix (what nodes each element is made up of) (inpoel), boundary face data (bface), elements surrounding elements (esuel), face connectivity data (intfac), faces making up an element (elemface) etc are stored as global arrays. This means that h-adpatation will be tough to incorporate at a later stage, while allowing faster iteration over elements and faces. Even if we move to local storage of mesh data at a (much) later stage, the current structures will be used to pre-compute that.

Storage of precomputed FE data
-----------------------------------
Storage of various quantities at quadrature points, such as physical coordinates, basis function values, basis gradient values, geometric mapping Jacobians and normals etc are stored locally in element-level class objects. If only mesh data is also included in these classes, h-adaptation can be incorporated. Also, effecient p-adaptation, without pre-allocating based on the maximum p requirement for all elements, is possible. If no adaptation (or only p-adaptation with allocation based on maximum p) is needed , a gobal array of these element-local objects can be stored. If adaptation is needed, we can store a linked list of these objects. Both these would correspond to the so-called "array-of-structs" storage.

The other option is to have global arrays of all the data needed. This would make a massive redesign necessary in case we wish to introduce adaptation. However, we get a "struct-of-arrays" type storage, which is supposedly better for memory access patterns. At this point, I do not see why that might be, and therefore nor how much better it is.

Current policy regarding Eigen's Matrix and Array2d
---------------------------------------------------
Storage for the purpose of only entry-wise access is done using Array2d. Eg. a list of coordinates of some points.
Storage of matrices and vectors in the linear algebra sense, when matrix and vector operations would be needed, is done using Eigen's Matrix class. Eg. sorage of Jacobian inverses and gradients of test basis functions.

Sparse matrix storage and solvers
---------------------------------
One option is to store as a block sparse matrix, either "block LU" or block CSR. This would enable usage of block solvers, like block Jacobi (BJ), block SGS (BSGS), block ILU (BILU) etc. The other option is to store as regular CSR and use point-solvers.

If we want to fit the block in L1 cache of 32 KB, we can have a max of 64 doubles in the block. The maximum we can go for Euler or laminar Navier-Stokes are as follows. 
2D: Triangular no. of DOFS: P4, Rectagular number of DOFs: P3 (but only just)
3D: Tet no. of DOFs: P2, Prism no. of DOFs: P1, Pyramid number of DOFs: P1, Hex number of DOFs: P1

For L2 cache, assuming 128 KB, for 1-equation RANS (5 variables in 2D, 6 in 3D) 
2D: Triangular no. of DOFs: P5, Rectangular no. of DOFs: P4
3D: Hex no. of DOFs: P1

However, even for high-order in 3D, it might be useful to store in a block format and use BLAS/Lapack calls for dense block operations, because BLAS/Lapack would hopefully split the operations into smaller sub-blocks.
*/

